---
title: "baselineModel"
output: html_document
---
```{r}
library(ggplot2)
library(tidyverse)
library(stringr)
library(GGally)
library(parcoords)
library(tidyr)
library(r2d3)
library(dplyr)
library(readr)
library(gridExtra)
library(plotly)
library(ade4)
library(data.table)
library(caret)
library(devtools) #inorder to use install_version
#most current version of xgboost can't be installed on the Rstudio server, thus
#install the older version: xgboost_0.90.0.2.tar.gz	2019-08-01 21:20	826K
#install_version("xgboost", version = "0.90.0.2", repost = "http://cran.us.r-project.org")
library(xgboost)
library(MLmetrics)#for calculating F1-score
library(ranger) #fast random forest
library(Boruta)
#rm(list=setdiff(ls(), "data")) command to clean the environment list
```


```{r}
#install.packages('RJDBC')

## --------------------------------
## Sets Java Home
## --------------------------------
if (Sys.getenv("JAVA_HOME")!="")  Sys.setenv(JAVA_HOME="")


## --------------------------------
## Loads libraries
## --------------------------------
library(rJava)
options(java.parameters = "-Xmx8048m")
library(RJDBC)
library(DBI)


## --------------------------------
## Sets Java Home
## --------------------------------
if (Sys.getenv("JAVA_HOME")!="")
  Sys.setenv(JAVA_HOME="")


## --------------------------------
## Loads libraries
## --------------------------------
library(rJava)
options(java.parameters = "-Xmx8048m")
library(RJDBC)
library(DBI)


## --------------------------------
## General Variables
## --------------------------------
redShiftDriver <- JDBC("com.amazon.redshift.jdbc41.Driver", "RedshiftJDBC41-1.2.8.1005.jar", identifier.quote="`")
# put Redshift jar file in your home directory
resultSet <- data.frame()
username <- "zfan4"               ## Set VPCx / Redshift username - this is your J&J userID, for example mine is stong2  
password <- "19A3#a39F7py"            ## Set VPCx / Redshift password - this is the password you got from an encrypted email
rhealthDBName <- "saf"                ## Set dataset you want to connect to (full list provided here:  https://jnj.sharepoint.com/sites/PHM-GCSP-RND/RWE/Pages/rHEALTH-Database-Connectivity.aspx)


## --------------------------------
## Connection (do not change)
## --------------------------------
connectionString <- paste("jdbc:redshift://rhealth-prod-4.cldcoxyrkflo.us-east-1.redshift.amazonaws.com:5439/", rhealthDBName,"?ssl=true&sslfactory=com.amazon.redshift.ssl.NonValidatingFactory", sep="")
conn <- dbConnect(redShiftDriver, connectionString, username, password)


# dbListTables(conn)

res <- dbSendQuery(conn,'select * from saf.scratch_ctsaf2.np_col_hipfx_ads_v9') ## CTSAF2 is my scratch space
data <- fetch(res,n = -1) 

```

```{r}
df_medicare <- data
dim(df_medicare)
```

```{r}
#----------------
# Data Cleaning
#----------------

# Remove target information (247 -184 = 63)

drops <- c('mortality_365', 'readm_flag_365', 'er_365days', 're_claim_no',  're_clm_admsn_dt', 're_nch_bene_dschrg_dt','re_prvdr_num', 're_clm_utlztn_day_cnt', 're_clm_pmt_amt', 're_pdx', 're_ppx', 're_adm_source', 're_disc_status', 're_pdx_desc', 're_ppx_desc', 're_clm_admsn_dt_365', 're_nch_bene_dschrg_dt_365', 're_prvdr_num_365', 're_clm_utlztn_day_cnt_365', 're_clm_pmt_amt_365', 're_pdx_365', 're_ppx_365', 're_adm_source_365', 're_claim_no_365', 're_disc_status_365', 're_pdx_desc_365', 're_ppx_desc_365', 're_claim_no_365_up', 'readm_flag_365_up', 're_clm_admsn_dt_365_up', 're_nch_bene_dschrg_dt_365_up', 're_prvdr_num_365_up', 're_clm_utlztn_day_cnt_365_up', 're_clm_pmt_amt_365_up', 're_pdx_365_up', 're_ppx_365_up', 're_adm_source_365_up', 're_disc_status_365_up', 're_pdx_desc_365_up', 're_ppx_desc_365_up', 'er_claim_no_365', 'er_rev_cntr_dt_365', 'er_clm_thru_dt_365', 'er_prncpal_dgns_cd_365', 'er_pdx_desc_365', 'er_hcpcs_cd_365', 'er_hcpcs_desc_365', 'mortality_365_up', 'er_365days_up', 'er_claim_no_365_up', 'er_rev_cntr_dt_365_up', 'er_clm_thru_dt_365_up', 'er_prncpal_dgns_cd_365_up', 'er_pdx_desc_365_up', 'er_hcpcs_cd_365_up', 'er_hcpcs_desc_365_up','er_claim_no', 'er_rev_cntr_dt', 'er_clm_thru_dt','er_prncpal_dgns_cd','er_pdx_desc', 'er_hcpcs_cd', 'er_hcpcs_desc')


df_medicare <- df_medicare[, !(colnames(df_medicare) %in% drops)]


# Remove collinear features (184 - 150 = 32)
# also remove county related information
drops <- c('cci_score_1825_days_b','elix_score_1825_days_b',  'fci_score_1825_days_b', 'follow_up_end_dt', 'follow_up_end_dt_365','ppx_desc', 'pdx_desc','hospital_name', 'fy', 'yr_adm', 'yr_disch', 'prvdr_state_name', 'prvdr_state_cd', 'prvdr_ssa_county_code', 'prov_vol_per_month', 'prvdr_home_hha_vol_month', 'prvdr_home_hha_vol_per', 'phy_vol_month', 'prvdr_urspa', 'prvdr_cbsa', 'prvdr_cbsa_desc', 'prvdr_msa','prvdr_msa_desc', "elix_cong_heart_fail_1825_days_b", "elix_periph_vas_dis_1825_days_b", "elix_paralysis_1825_days_b", "elix_copd_1825_days_b", "elix_aids_1825_days_b", "elix_met_cancer_1825_days_b", "fci_heart_attack_1825_days_b", "fci_obesity_1825_days_b", 'nch_bene_dschrg_dt','county', 'bene_cnty_cd')

df_medicare <- df_medicare[, !(colnames(df_medicare) %in% drops)]


# Remove features same entry and unique entry (150 - 136 = 14)

drops <- c('version_id', 'cont_enroll_flag_1825b_89f', 'valid_date_of_death_1825b_89f', 'hmo_enroll_flag_1825b_89f', 'hmo_enroll_flag_365f','cont_enroll_flag_365f','at_physn_upin', 'op_physn_upin', 'ot_physn_upin',
           'desy_sort_key', 'claim_no', 'ot_physn_npi','at_physn_npi','op_physn_npi')


df_medicare <- df_medicare[, !(colnames(df_medicare) %in% drops)]

# Remove missing value (439248 - 429599 = 9649)

# remove rows with missing value
df_medicare[df_medicare == -999] <- NA
df_medicare[df_medicare == 'NA'] <- NA
df_medicare <- df_medicare %>% drop_na(prvdr_num,prvdr_teaching_status,ma_pen_percent,prvdr_rday,ami_cabg)

```




```{r}
# The following code is to check whether there is still missing value left
# t <- colSums(is.na(df_medicare))
# t[t!=0]
```


```{r}

#-----------
# Hospital level and Population level Sampling
#-----------

##removing hospital with less than 100 observations and less than 10 positive or negative value for the target variables
keep = df_medicare %>% 
  group_by(prvdr_num) %>% 
  summarise(total = n(), re_pos = sum(readm_flag), re_neg = total - re_pos, er_pos = sum(er_90days), er_neg = total - er_pos, mor_pos = sum(mortality_90), mor_neg = total - mor_pos) %>% 
  filter(total > 99 & re_pos > 10 & re_neg > 10 & er_pos > 10 & er_neg > 10 & mor_pos > 10 & mor_neg > 10 ) %>% 
  pull(prvdr_num)
hos_sample <- df_medicare %>% 
  filter(prvdr_num %in% keep)
```

```{r}
set.seed(100)
#random sample 5% hospital based on the state
keep <- hos_sample %>% 
  group_by(prvdr_num) %>% 
  summarise(number = length(prvdr_num),state = unique(prvdr_state_ab),type = unique(provider_type)) %>%
  group_by(state) %>%
  sample_n(as.integer(ceiling(length(state)/20))) %>%
  pull(prvdr_num)

#Since there is only one "Hospitals participating in ORD demonstration project" prvdr_num = 450890 fits our previous criteria, thus must include it in our sample
if (! "450890" %in% keep){
  keep = c(keep, "450890")
}
hos_sample <- hos_sample %>% 
  filter(prvdr_num %in% keep)

## plots to test the sample
# t1 <- df_medicare %>%
#   group_by(prvdr_state_ab) %>%
#   summarise(num = length(prvdr_state_ab),hos_num = length(unique(prvdr_num)),type = "population")
# t2 <- hos_sample %>%
#   group_by(prvdr_state_ab) %>%
#   summarise(num = length(prvdr_state_ab),hos_num = length(unique(prvdr_num)),type = "sample")
# t <- rbind(t1,t2) 
# 
# ggplot(data=t, aes(x = reorder(prvdr_state_ab,num), y=log(num)))+
#   geom_bar(stat="identity",fill = "steelblue") +
#   coord_flip() +
#   xlab('state')+ 
#   ylab('number of patients(log)') +
#   facet_wrap(~ type) + 
#   theme_minimal()
# 
# ggplot(data=t, aes(x = reorder(prvdr_state_ab,hos_num), y=log(hos_num)))+
#   geom_bar(stat="identity",fill = "steelblue") +
#   coord_flip() +
#   xlab('state')+ 
#   ylab('number of hospitals(log)') +
#   facet_wrap(~ type) + 
#   theme_minimal()

population_sample <- hos_sample
 
# Remove columns leaking hospital information
drops <- c('fci_arthritis_1825_days_b', 'fci_osteoporosis_1825_days_b', 'fci_asthma_1825_days_b', 'fci_copd_1825_days_b', 'fci_angina_1825_days_b', 'fci_cong_heart_fail_1825_days_b', 'fci_heart_attack_1825_days_b', 'fci_neur_dis_1825_days_b', 'fci_stroke_1825_days_b', 'fci_diabetes_1825_days_b', 'fci_perif_vasc_dis_1825_days_b', 'fci_upper_gi_1825_days_b', 'fci_depression_1825_days_b', 'fci_anxiety_panic_1825_days_b', 'fci_visual_imp_1825_days_b', 'fci_hear_imp_1825_days_b', 'fci_ddd_1825_days_b', 'fci_obesity_1825_days_b', 'prvdr_state_cd', 'prov_vol_annual', 'prov_vol_per_month', 'prvdr_home_hha_vol', 'prvdr_home_hha_vol_month', 'prvdr_home_hha_vol_per', 'phy_vol_annual', 'phy_vol_month', 'op_phy_cum_exp', 'provider_type', 'hospital_name', 'prvdr_ssa_county_code', 'prvdr_urgeo', 'prvdr_urspa', 'prvdr_wi', 'prvdr_cola', 'prvdr_resident_to_bed_ratio', 'prvdr_rday', 'prvdr_beds', 'prvdr_dshpct', 'prvdr_dshopg', 'prvdr_dshcpg', 'prvdr_state_name', 'prvdr_state_ab', 'prvdr_div_code', 'prvdr_division', 'prvdr_region_cd', 'prvdr_region','county', 'bpci_lejr', 'cjr', 'bpci_ami_cabg', 'ami_cabg', 'prvdr_cbsa', 'prvdr_cbsa_desc', 'prvdr_msa', 'prvdr_msa_desc', 'prvdr_teaching_status', 'low_income_subsidy', 'prior_inp_only_los', 'prior_irf_los', 'prior_ltcf_los', 'prior_snf_los', 'prior_hha_visits', 'prior_out_visits', 'total_prior_los', 'poverty_per', 'grp_1', 'grp_2', 'grp_3', 'grp_4', 'grp_5', 'grp_6', 'grp_7', 'grp_8', 'grp_9', 'grp_10', 'unemp_percentage', 'no_of_snfs', 'ma_pen_percent', 'snf_per_capita')

hos_sample <- hos_sample[, !(colnames(hos_sample) %in% drops)]

```
```{r}

# Note all the Critical Access Hospitals has hospital name associate variables as N/A, such as prvdr_wi, prvdr_rday
# Also note only 2 Critical Access Hospital has over 100 observation and one with readmit only 8 positive.
# Other type of hospitals has less than 100 observations beside short-term and "Hospitals participating in ORD demonstration project" (only 1 hospital(361319) of this type has over 100 observation)
# test_hospital_type = data %>% filter(provider_type == "Critical Access Hospitals" )
# temp = test_hospital_type %>% 
#   group_by(prvdr_num) %>% 
#   summarise(total = n(), re_pos = sum(readm_flag), re_neg = total - re_pos, 
#             er_pos = sum(er_90days), er_neg = total - er_pos,
#             mor_pos = sum(mortality_90), mor_neg = total - mor_pos)
# test_hospital_type = df_medicare %>% filter(provider_type == "Hospitals participating in ORD demonstration project" )
# temp = test_hospital_type %>% 
#   group_by(prvdr_num) %>%
#   summarise(total = n(), re_pos = sum(readm_flag), re_neg = total - re_pos,
#             er_pos = sum(er_90days), er_neg = total - er_pos,
#             mor_pos = sum(mortality_90), mor_neg = total - mor_pos)



```


```{r}
###df_medicare_state <- df_medicare %>% group_by(prvdr_state_name) %>% summarise(number = length(prvdr_state_name), sample = as.integer(length(prvdr_state_name)/10) )
## for histogram (entire dataset)

# ----------------- 
#Population Sampling
# -----------------
# set.seed(100) #for reproduce purpose
# population_sample <- df_medicare %>% group_by(prvdr_state_ab) %>% sample_n(as.integer(ceiling(length(prvdr_state_ab)/20)))
```

```{r}
# -------------------
# feature engineering
# -------------------

# Add time related features for later use
population_sample$clm_admsn_dt = as.Date(population_sample$clm_admsn_dt)
population_sample$month = months(population_sample$clm_admsn_dt,abbreviate = TRUE)
population_sample$week_of_dates = weekdays(population_sample$clm_admsn_dt,abbreviate = TRUE)

#change difftime object to numeric
population_sample$days_before_admsn = as.numeric(population_sample$clm_admsn_dt-as.Date('2016-01-01'), units="days")

#no need the days_before_dscharg as we already have length of stay and is removed from data in the collinearity section
#remove date column as we have convert it to number
drops = c('clm_admsn_dt')
population_sample = population_sample[,!(colnames(population_sample) %in% drops)]

#for later target encoder use
population_sample[sapply(population_sample, is.character)] <- lapply(population_sample[sapply(population_sample, is.character)], as.factor)
```


```{r}
# ----------------- 
# train validation test split
# -----------------

# we focus on readmission now. so we remove mortality and er_90days 
drops<- c('mortality_90', 'er_90days')
population_sample <- population_sample[,!(colnames(population_sample) %in% drops)]

#create an empty data frame
train = population_sample[1,] %>% filter(prvdr_num == "empty")
val = population_sample[1,] %>% filter(prvdr_num == "empty")
test = population_sample[1,] %>% filter(prvdr_num == "empty")

# population train, val, test = sum of all hospital's train set, val, test
n_of_hos = unique(population_sample$prvdr_num)
for(h in n_of_hos){
  temp = population_sample %>% filter(prvdr_num == h)
  size = nrow(temp)
  train_size = as.integer(round(size*0.7, digits = 0))
  val_size = as.integer(round(size*0.15, digits = 0))
  h_train = temp[c(1:train_size),]
  h_val = temp[c((train_size+1):(train_size + val_size)),]
  h_test = temp[c((train_size + val_size+1):size),]
  train = rbind(train, h_train)
  val = rbind(val, h_val)
  test = rbind(test, h_test)
  
}

#for population model only
train <- train[, !(colnames(train) %in% c("prvdr_num"))]
val <- val[, !(colnames(val) %in% c("prvdr_num"))]
test <- test[, !(colnames(test) %in% c("prvdr_num"))]

```


```{r}
# ----------------- 
# Data Preprocessing
# -----------------

#target encoding for categorical features

addrandom = function(x){
  return(x + runif(1))
}
targetencode = function(indices, df){
  result = c()
  df$fake_target = sapply(df$readm_flag, addrandom)
  for (i in indices){
    lookup = df %>% group_by_at(i) %>% summarise(mean(fake_target))
    result = c(result, lookup)
  }
  return(result)
}

targetencode_transform = function(indices, result, df, dropna = TRUE){
  j = 1
  for (i in indices){
    lookup = data.frame(result[j], result[j+1])
    cat_colname = colnames(df)[i]
    df_targetment = left_join(df[cat_colname], lookup, by = cat_colname)
    df[i] = df_targetment[, 2]
    j = j +2
  }
  if (dropna & sum(is.na(df))){
    print("There is missing categorical class")
    t <- colSums(is.na(df))
    print(t[t!=0])
    df = df %>% drop_na()
  }
  return(df)
}
cat_name = names(Filter(is.factor, train))
cat_index = match(cat_name, names(train))
tgen = targetencode(cat_index, train)
train = targetencode_transform(cat_index, tgen, train)
val = targetencode_transform(cat_index, tgen, val)
test = targetencode_transform(cat_index, tgen, test)
```

```{r}

# ----------------- 
# Data Preparation -variables grouping
# -----------------
sm_train_size = 1000
sm_val_size = 500
sm_test_size = 100

train = train[c(1:sm_train_size),]
val = val[c(1:sm_val_size),]
test = test[c(1:sm_test_size),]

#base, Boruta, Boruta + time, base + time as index 1, 2, 3, 4
train_set = list()
val_set = list()

# # dataset for base model (remove time related features)
time_feature = c('month','week_of_dates','days_before_admsn')
train_set[[1]] = train[,!(colnames(train) %in% time_feature)]
val_set[[1]] = val[,!(colnames(val) %in% time_feature)]

## Boruta with no time data set
boruta_start_time <- Sys.time()
sigtest <- Boruta(readm_flag~. , data = train, holdHistory=FALSE, doTrace=2)
boruta_end_time <- Sys.time()
boruta_features = c(getSelectedAttributes(sigtest), "readm_flag")
train_set[[2]] = train[, boruta_features]
val_set[[2]] = val[, boruta_features]
print(boruta_end_time - boruta_start_time)

## Boruta with time data set
boruta_time_features = c(boruta_features, time_feature)
train_set[[3]] = train[, boruta_time_features]
val_set[[3]] = val[, boruta_time_features]

## Base with time data set
train_set[[4]] = train 
val_set[[4]] = val 
```

```{r}
# ----------------- 
# Train Model
# -----------------

fitModel = function(df,type){
  
  folds <- 5
  cvIndex <- createFolds(df$readm_flag, folds, returnTrain = T)
  df$readm_flag =as.factor(df$readm_flag) 
  levels(df$readm_flag)= c("Class_0", "Class_1")
  df$readm_flag <- factor(df$readm_flag,    levels=rev(levels(df$readm_flag)))
  y_train = df$readm_flag
  st = Sys.time()
  if(type == 'rlg'){
    trcontrol = trainControl(index = cvIndex,
                              method = "cv",
                              number = folds,
                              summaryFunction = prSummary,
                              classProbs = TRUE)
    set.seed(0)
    fit <- train(
      form = readm_flag ~., 
      data = df,
      trControl= trcontrol,
      method = 'regLogistic',
      metric = "F")
  }
  else if(type == 'rf'){
    trcontrol = trainControl(index = cvIndex,
                              method = "cv",
                              number = folds,
                              summaryFunction = prSummary,
                              classProbs = TRUE)
    set.seed(0)
    fit <- train(
      form = readm_flag ~., 
      data = df,
      trControl= trcontrol,
      method = 'ranger',
      metric = "F")
  }
  else if(type == 'xgb'){
    df = df %>% select(-readm_flag)
    X_train = xgb.DMatrix(as.matrix(df))
    
    trcontrol = trainControl(
      index = cvIndex,
      method = "cv",
      number = folds,  
      allowParallel = TRUE,
      verboseIter = FALSE,
      classProbs = TRUE,
      summaryFunction = prSummary,
      returnData = FALSE
    )
    set.seed(0) 
    fit = train(
      X_train, y_train,  
      trControl = trcontrol,
      nthread = 1, #avoid double parallel computing causing the run time to expand 
      method = "xgbTree",
      metric = "F"
    )
  }
  ed = Sys.time()
  print(ed - st)
  return(fit)
}
```


```{r}
#F1 Score note

#Note if TP + FP ==0 (when we all predict 0), precision is undefined.
#Precision = TP / (TP+FP)
#Recall = TP/(TP + FN)

#if TP + FN == 0 (when sample only have 0), recall is undefined
#F1 = 2 * Precision * Recall/ (Precision + Recall) -> undefined if TP = 0


# ConfusionMatrix
#         ACTUAL
#        1     0
# P    +----+----+
# R  1 | TP | FP |
# E    +----+----+
# D  0 | FN | TN |
#      +----+----+

# since if we predict all as Class 0 or as Class 1, F1_score will return error, plus we don't want a model that predict all as 0 or 1, thus set its f1 score = -1 indicate bad model
unbias_f1 = function(pred, yval){
  f1 = -1
  if (sum(pred)!= 0 & sum(pred)!= length(pred)){
    f1 = F1_Score( y_pred = pred, y_true = yval, positive = 1)
  }else if(sum(pred) == sum(yval)){
    f1 = 1
  }
  return(f1)
}

# ----------------- 
# Prediction
# -----------------
#scoring function returns a list of best Cross_Validation Score, Validation Set F1 scores, Log loss, AUC, and Accuracy with input model, X validation and y validation.
scoring = function(model, X_val, y_val){
  pre_class <- ifelse(predict(model, newdata = X_val, type = "raw") == "Class_0",0,1)
  pre_prob <- predict(model, newdata = X_val, type = "prob")$Class_1
  return(c(max(model$results$F, na.rm=TRUE), unbias_f1(pre_class, y_val), LogLoss(pre_prob, y_val), AUC(pre_prob, y_val), Accuracy(pre_class, y_val)))
}

```


```{r}
model_types = c("rlg", "rf", "xgb")
X_types = c("Base", "Boruta", "Boruta_time", "Base_time")
model_X_types = c()
cv_f1s = c()
val_f1s = c()
loglosses = c()
AUCs = c()
accuracys = c()
models = list()
st = Sys.time()
for(type in model_types){
  j = 1
  for(i in c(1:4)){
    model_X_type = paste(type, X_types[i], sep= "_")
    model_X_types = c(model_X_types, model_X_type)
    train_df = train_set[[i]]
    y_val = val_set[[i]]$readm_flag
    X_val = val_set[[i]] %>% select(-readm_flag)
    if(type == "xgb"){
      X_val = xgb.DMatrix(as.matrix(X_val))
    }
    model = fitModel(train_df, type)
    sc = scoring(model, X_val, y_val)
    cv_f1s = c(cv_f1s, sc[1])
    val_f1s = c(val_f1s, sc[2])
    loglosses = c(loglosses, sc[3])
    AUCs = c(AUCs, sc[4])
    accuracys = c(accuracys, sc[5])
    models[[j]] = model
    j = j +1
  }
}
print(Sys.time()-st)
```

```{r}
summary_result <- data.frame("Type" =model_X_types, "cv_f1" = cv_f1s, "val_f1" = val_f1s, "logloss" = loglosses, "AUC" = AUCs, "accuracy" = accuracys, stringsAsFactors = FALSE)
best_cvf1 = max(summary_result$val_f1)
best_index = which.max(summary_result$val_f1)
best_model_name = model_X_types[best_index]
best_model = models[[best_index]]

print(paste("The best model is:", best_model_name, "with validation f1 score:", best_cvf1, sep = " "))
```





