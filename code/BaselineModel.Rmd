---
title: "baselineModel"
output: html_document
---
```{r}
library(ggplot2)
library(tidyverse)
library(stringr)
library(GGally)
library(parcoords)
library(tidyr)
library(r2d3)
library(dplyr)
library(readr)
library(gridExtra)
library(plotly)
library(ade4)
library(data.table)
library(caret)
library(devtools) #inorder to use install_version
#most current version of xgboost can't be installed on the Rstudio server, thus
#install the older version: xgboost_0.90.0.2.tar.gz	2019-08-01 21:20	826K
#install_version("xgboost", version = "0.90.0.2", repost = "http://cran.us.r-project.org")
library(xgboost)
```


```{r}
#install.packages('RJDBC')

## --------------------------------
## Sets Java Home
## --------------------------------
if (Sys.getenv("JAVA_HOME")!="")  Sys.setenv(JAVA_HOME="")


## --------------------------------
## Loads libraries
## --------------------------------
library(rJava)
options(java.parameters = "-Xmx8048m")
library(RJDBC)
library(DBI)


## --------------------------------
## Sets Java Home
## --------------------------------
if (Sys.getenv("JAVA_HOME")!="")
  Sys.setenv(JAVA_HOME="")


## --------------------------------
## Loads libraries
## --------------------------------
library(rJava)
options(java.parameters = "-Xmx8048m")
library(RJDBC)
library(DBI)


## --------------------------------
## General Variables
## --------------------------------
redShiftDriver <- JDBC("com.amazon.redshift.jdbc41.Driver", "RedshiftJDBC41-1.2.8.1005.jar", identifier.quote="`")
# put Redshift jar file in your home directory
resultSet <- data.frame()
username <- "zfan4"               ## Set VPCx / Redshift username - this is your J&J userID, for example mine is stong2  
password <- "19A3#a39F7py"            ## Set VPCx / Redshift password - this is the password you got from an encrypted email
rhealthDBName <- "saf"                ## Set dataset you want to connect to (full list provided here:  https://jnj.sharepoint.com/sites/PHM-GCSP-RND/RWE/Pages/rHEALTH-Database-Connectivity.aspx)


## --------------------------------
## Connection (do not change)
## --------------------------------
connectionString <- paste("jdbc:redshift://rhealth-prod-4.cldcoxyrkflo.us-east-1.redshift.amazonaws.com:5439/", rhealthDBName,"?ssl=true&sslfactory=com.amazon.redshift.ssl.NonValidatingFactory", sep="")
conn <- dbConnect(redShiftDriver, connectionString, username, password)


# dbListTables(conn)

res <- dbSendQuery(conn,'select * from saf.scratch_ctsaf2.np_col_hipfx_ads_v9') ## CTSAF2 is my scratch space
data <- fetch(res,n = -1) 

```

```{r}
df_medicare <- data
dim(df_medicare)
```

Remove target information
```{r}
columns_having_target_info <- c('mortality_365', 'readm_flag_365', 'er_365days', 're_claim_no',  're_clm_admsn_dt', 're_nch_bene_dschrg_dt','re_prvdr_num', 're_clm_utlztn_day_cnt', 're_clm_pmt_amt', 're_pdx', 're_ppx', 're_adm_source', 're_disc_status', 're_pdx_desc', 're_ppx_desc', 're_clm_admsn_dt_365', 're_nch_bene_dschrg_dt_365', 're_prvdr_num_365', 're_clm_utlztn_day_cnt_365', 're_clm_pmt_amt_365', 're_pdx_365', 're_ppx_365', 're_adm_source_365', 're_claim_no_365', 're_disc_status_365', 're_pdx_desc_365', 're_ppx_desc_365', 're_claim_no_365_up', 'readm_flag_365_up', 're_clm_admsn_dt_365_up', 're_nch_bene_dschrg_dt_365_up', 're_prvdr_num_365_up', 're_clm_utlztn_day_cnt_365_up', 're_clm_pmt_amt_365_up', 're_pdx_365_up', 're_ppx_365_up', 're_adm_source_365_up', 're_disc_status_365_up', 're_pdx_desc_365_up', 're_ppx_desc_365_up', 'er_claim_no_365', 'er_rev_cntr_dt_365', 'er_clm_thru_dt_365', 'er_prncpal_dgns_cd_365', 'er_pdx_desc_365', 'er_hcpcs_cd_365', 'er_hcpcs_desc_365', 'mortality_365_up', 'er_365days_up', 'er_claim_no_365_up', 'er_rev_cntr_dt_365_up', 'er_clm_thru_dt_365_up', 'er_prncpal_dgns_cd_365_up', 'er_pdx_desc_365_up', 'er_hcpcs_cd_365_up', 'er_hcpcs_desc_365_up','er_claim_no', 'er_rev_cntr_dt', 'er_clm_thru_dt','er_prncpal_dgns_cd','er_pdx_desc', 'er_hcpcs_cd', 'er_hcpcs_desc')


df_medicare <- df_medicare[, !(colnames(df_medicare) %in% columns_having_target_info)]
```

Remove collinear features
```{r}
columns_having_collinearity <- c('cci_score_1825_days_b','elix_score_1825_days_b',  'fci_score_1825_days_b', 'follow_up_end_dt', 'follow_up_end_dt_365','ppx_desc', 'pdx_desc')

df_medicare <- df_medicare[, !(colnames(df_medicare) %in% columns_having_collinearity)]

hos_num <- df_medicare$prvdr_num

add_colinear <- c('prvdr_num','fy','yr_adm','yr_disch','prvdr_state_name','prvdr_state_cd','prvdr_ssa_county_code','prov_vol_per_month','prvdr_home_hha_vol_month','prvdr_home_hha_vol_per','phy_vol_month','prvdr_urspa','prvdr_cbsa','prvdr_cbsa_desc','prvdr_msa','prvdr_msa_desc', "elix_cong_heart_fail_1825_days_b", "elix_periph_vas_dis_1825_days_b", "elix_paralysis_1825_days_b","elix_copd_1825_days_b","elix_aids_1825_days_b", "elix_met_cancer_1825_days_b",     "fci_heart_attack_1825_days_b","fci_obesity_1825_days_b" )


df_medicare <- df_medicare[, !(colnames(df_medicare) %in% add_colinear)]


```

Remove features same entry and unique entry
```{r}
columns_no_variance <- c('version_id', 'cont_enroll_flag_1825b_89f', 'valid_date_of_death_1825b_89f', 'hmo_enroll_flag_1825b_89f', 'hmo_enroll_flag_365f','cont_enroll_flag_365f','at_physn_upin', 'op_physn_upin', 'ot_physn_upin')

columns_unique <- c('desy_sort_key', 'claim_no', 'ot_physn_npi','at_physn_npi','op_physn_npi')

df_medicare <- df_medicare[, !(colnames(df_medicare) %in% columns_no_variance)]

df_medicare <- df_medicare[, !(colnames(df_medicare) %in% columns_unique)]
```

Remove missing value
```{r}
# remove columns with missing value
# df_medicare <- df_medicare[,df_medicare %>% is.na() %>% colSums() == 0]

# remove rows with missing value
df_medicare[df_medicare == -999] <- NA
df_medicare[df_medicare == 'NA'] <- NA
df_medicare <- df_medicare %>% drop_na(hospital_name,prvdr_teaching_status,ma_pen_percent,prvdr_rday,ami_cabg)
# The following code is to check whether there is still missing value left
# df_medicare <- df_medicare[df_medicare %>% is.na() %>% rowSums() == 0,]
# t <- colSums(is.na(df_medicare))
# t[t!=0]
```

Remove columns leaking hospital information
```{r}

columns_hospital_info <- c('fci_arthritis_1825_days_b', 'fci_osteoporosis_1825_days_b', 'fci_asthma_1825_days_b', 'fci_copd_1825_days_b', 'fci_angina_1825_days_b', 'fci_cong_heart_fail_1825_days_b', 'fci_heart_attack_1825_days_b', 'fci_neur_dis_1825_days_b', 'fci_stroke_1825_days_b', 'fci_diabetes_1825_days_b', 'fci_perif_vasc_dis_1825_days_b', 'fci_upper_gi_1825_days_b', 'fci_depression_1825_days_b', 'fci_anxiety_panic_1825_days_b', 'fci_visual_imp_1825_days_b', 'fci_hear_imp_1825_days_b', 'fci_ddd_1825_days_b', 'fci_obesity_1825_days_b', 
'prvdr_state_cd', 'prov_vol_annual', 'prov_vol_per_month', 'prvdr_home_hha_vol', 'prvdr_home_hha_vol_month', 'prvdr_home_hha_vol_per', 'phy_vol_annual', 'phy_vol_month', 'op_phy_cum_exp', 'provider_type', 'hospital_name', 'prvdr_ssa_county_code', 'prvdr_urgeo', 'prvdr_urspa', 'prvdr_wi', 'prvdr_cola', 'prvdr_resident_to_bed_ratio', 'prvdr_rday', 'prvdr_beds', 'prvdr_dshpct', 'prvdr_dshopg', 'prvdr_dshcpg', 'prvdr_state_name', 'prvdr_state_ab', 'prvdr_div_code', 'prvdr_division', 'prvdr_region_cd', 'prvdr_region','county', 'bpci_lejr', 'cjr', 'bpci_ami_cabg', 'ami_cabg', 'prvdr_cbsa', 'prvdr_cbsa_desc', 'prvdr_msa', 'prvdr_msa_desc', 'prvdr_teaching_status', 'low_income_subsidy', 'prior_inp_only_los', 'prior_irf_los', 'prior_ltcf_los', 'prior_snf_los', 'prior_hha_visits', 'prior_out_visits', 'total_prior_los', 'poverty_per', 'grp_1', 'grp_2', 'grp_3', 'grp_4', 'grp_5', 'grp_6', 'grp_7', 'grp_8', 'grp_9', 'grp_10', 'unemp_percentage', 'no_of_snfs', 'ma_pen_percent', 'snf_per_capita')


df_medicare <- df_medicare[, !(colnames(df_medicare) %in% columns_hospital_info)]


```


```{r}
###df_medicare_state <- df_medicare %>% group_by(prvdr_state_name) %>% summarise(number = length(prvdr_state_name), sample = as.integer(length(prvdr_state_name)/10) )
## for histogram (entire dataset)

# ----------------- 
#Population Sampling
# -----------------
set.seed(100) #for reproduce purpose
population_sample <- df_medicare %>% group_by(prvdr_state_ab) %>% sample_n(as.integer(ceiling(length(prvdr_state_ab)/20)))
```

```{r}
# -------------------
# feature engineering
# -------------------

# convert variable to date feature 
population_sample$nch_bene_dschrg_dt = as.Date(population_sample$nch_bene_dschrg_dt)
population_sample$clm_admsn_dt = as.Date(population_sample$clm_admsn_dt)

# standardize all numeric column
# population_sample=population_sample %>% mutate_if(is.numeric, scale)

# one hot encoder
# df_zhao=population_sample
# 
# ohe_feats = names(Filter(is.factor, df_zhao))
# for (f in ohe_feats){
#   df_all_dummy = acm.disjonctif(df_zhao[f])
#   df_zhao[f] = NULL
#   df_zhao = cbind(df_zhao, df_all_dummy)
# }


population_sample[sapply(population_sample, is.character)] <- lapply(population_sample[sapply(population_sample, is.character)], as.factor)
# df_zhao=population_sample

# target encoder (target is readmission)
target_encoder_readmit<- function(df_zhao){
  ohe_feats = names(Filter(is.factor, df_zhao))
  ohe_index = match(ohe_feats, names(df_zhao))
  for (f in ohe_index){
    # creating a lookup table
    lookup = df_zhao %>%group_by_at(f)%>%summarise(mean(readm_flag))
    temp = left_join(df_zhao[colnames(df_zhao)[f]], lookup,by=colnames(df_zhao)[f])
    df_zhao[f] = temp[,2]
  }
  return(df_zhao)
}

population_sample <- target_encoder_readmit(population_sample)
# target encoder has some shortcomings
```


Further Testing collinearity with findLinearCombos
```{r}
#date_info = c("clm_admsn_dt", "nch_bene_dschrg_dt")
#population_sample_nodt <- population_sample[, !(colnames(df_medicare) %in% date_info)]
#comboInfo <- findLinearCombos(population_sample_nodt)
#comboInfo
```

```{r}
#colnames(population_sample_nodt[, c(26, 10, 30, 11, 33, 20, 35, 14, 39, 21, 42, 25, 44, 25, 63, 9, 74, 48)])
#remove = colnames(population_sample_nodt[, comboInfo$remove])
#population_sample <- population_sample[, !(colnames(population_sample) %in% remove)]
```
```{r}
#remove
```

```{r}
# ----------------- 
# train population model
# -----------------

# we focus on readmission now. so we remove mortality and er_90days 
drops<- c('mortality_90', 'er_90days')
population_sample <- population_sample[,!(colnames(population_sample) %in% drops)]

# Add time related features
population_sample$clm_admsn_dt = as.Date(population_sample$clm_admsn_dt)
population_sample$nch_bene_dschrg_dt = as.Date(population_sample$nch_bene_dschrg_dt)
population_sample$month = months(population_sample$clm_admsn_dt,abbreviate = TRUE)
population_sample$week_of_dates = weekdays(population_sample$clm_admsn_dt,abbreviate = TRUE)
population_sample$days_before_admsn = population_sample$clm_admsn_dt-as.Date('2016-01-01')
population_sample$days_before_dschrg = population_sample$nch_bene_dschrg_dt - as.Date('2016-01-01')


#change target to factor
population_sample$readm_flag=as.factor(population_sample$readm_flag)

# hold out test set
population_sample = population_sample[order(population_sample$clm_admsn_dt),]
size = nrow(population_sample)
#create train for training model with cv method
train_size = as.integer(round(size*0.7,digits=0))
#crerate val for comparing models
val_size = as.integer(round(size*0.15,digits=0))
test_size = as.integer(size - train_size - val_size)

train = population_sample[c(1:train_size), ]
val = population_sample[c((train_size+1): (train_size + val_size)), ]
test = population_sample[c((train_size + val_size +1):size), ]

# dataset for base model (remove time related features)
drops = c('clm_admsn_dt','nch_bene_dschrg_dt','month','week_of_dates','days_before_admsn','days_before_dschrg')
train_base = train[,!(colnames(train) %in% drops)]
val_base = val[,!(colnames(val) %in% drops)]
test_base = test[,!(colnames(test) %in% drops)]



```

100,000
train(along with cv) 0.7 (whole data) 
validation (for deciding to model use) 0.15 (whole data)
test (only use once) 0.15 (whole data)


XGboost
```{r}
#Need numeric to turn into xgb.Dmatrix
try_data <-  train_base[c(1:200),]

X_train = xgb.DMatrix(as.matrix(try_data %>% select(-readm_flag)))
try_data$readm_flag =as.factor(try_data$readm_flag)
y_train = try_data$readm_flag
sm_test = test_base[c(1:100),]
X_test = xgb.DMatrix(as.matrix(sm_test %>% select(-readm_flag)))
y_test = as.factor(sm_test$readm_flag)

```

XGboost F1 Score

```{r}
#Reference: https://datascienceplus.com/extreme-gradient-boosting-with-r/
#Specify cross-validation method and number of folds. Also enable parallel computation
#The column “Kappa” is Cohen’s (unweighted) Kappa statistic averaged across the resampling results. 
#https://en.wikipedia.org/wiki/Cohen%27s_kappa#Properties
library(MLmetrics)
#F1 as score
#y_train might need to be factor form to apply level
#level replacing 0, 1 to "Class_0" and "Class_1" as variables due to classProbs need
levels(y_train) <- c("Class_0", "Class_1")
#to set Class_1 as positive class
y_train <- factor(y_train, levels=rev(levels(y_train)))
#R caret cv doesn't do stratified, meaning we migh have missing class in the sample
#Thus fix it by creating index inadvance
#Reference Code: https://stackoverflow.com/questions/35907477/caret-package-stratified-cross-validation-in-train-function
folds <- 5
cvIndex <- createFolds(factor(y_train), folds, returnTrain = T)
xgb_trcontrol_f1 = trainControl(
  index = cvIndex,
  method = "cv",
  number = folds,  
  allowParallel = TRUE,
  verboseIter = FALSE,
  classProbs = TRUE,
  #Need to install "MLmetrics" packages
  summaryFunction = prSummary,
  returnData = FALSE
)

#I am specifing the same parameters with the same values as I did for Python above. The hyperparameters to optimize are found in the website.
xgbGrid <- expand.grid(nrounds = c(100,200),  # this is n_estimators in the python code above
                       max_depth = c(10, 15, 20, 25),
                       colsample_bytree = seq(0.5, 0.9, length.out = 5),
                       ## The values below are default values in the sklearn-api. 
                       eta = 0.1,
                       gamma=0,
                       min_child_weight = 1,
                       subsample = 1
                      )
set.seed(0) 
xgb_model_f1 = train(
  X_train, y_train,  
  trControl = xgb_trcontrol_f1,
  tuneGrid = xgbGrid,
  method = "xgbTree",
  metric = "F"
)
```

```{r}
#Summary
xgb_model_f1$results
```
```{r}
#best tune result
xgb_model_f1$bestTune
```
```{r}
#obtain the best f1 score from the result
max(xgb_model_f1$results$F)
```



Reglogistic Regression
```{r}
#double check if there is na
colnames(try_data)[colSums(is.na(try_data)) > 0]
# ----------------- 
#   regLogistic
# -----------------
levels(try_data$readm_flag)= c("Class_0", "Class_1")
try_data$readm_flag <- factor(try_data$readm_flag, levels=rev(levels(try_data$readm_flag)))

train.control <- trainControl(index = cvIndex,
                              method = "cv",
                              number = folds,
                              summaryFunction = prSummary,
                              classProbs = TRUE)

logistic_fit <- train(form = readm_flag ~., 
                 data = try_data, 
                 method = 'regLogistic',
                 trControl=train.control ,
                 metric = "F")

```
Random Forest
```{r}
#double check if there is na
colnames(try_data)[colSums(is.na(try_data)) > 0]
# ----------------- 
#   rf
# -----------------
levels(try_data$readm_flag)= c("Class_0", "Class_1")
try_data$readm_flag <- factor(try_data$readm_flag, levels=rev(levels(try_data$readm_flag)))

train.control <- trainControl(index = cvIndex,
                              method = "cv",
                              number = folds,
                              summaryFunction = prSummary,
                              classProbs = TRUE)

rf_fit <- train(form = readm_flag ~., 
                 data = try_data, 
                 method = 'rf',
                 trControl=train.control ,
                 metric = "F")

```


Plot the distribution of each state
```{r,fig.height=6.5}

# to obtain summary based on provider's state
df_medicare_state <- df_medicare %>% group_by(prvdr_state_ab) %>% summarise(number = length(prvdr_state_ab),type = "population" )

test_state <- population_sample %>% group_by(prvdr_state_ab) %>% summarise(number =  length(prvdr_state_ab),type = "sample" )

df_medicare_state <- rbind(df_medicare_state,test_state)

ggplot(data=df_medicare_state, aes(x = reorder(prvdr_state_ab,number), y=log(number)))+
  geom_bar(stat="identity",fill = "steelblue") +
  coord_flip() +
  xlab('state')+ 
  ylab('number of patients(log)') +
  facet_wrap(~ type) + 
  theme_minimal()
```

plot for different hospital
```{r}

df_medicare_hos <- df_medicare %>% group_by(provider_type) %>% summarise(number = length(provider_type), type = "population" )

test_hos <- population_sample %>% group_by(provider_type) %>% summarise(number =  length(provider_type),type = "sample" )

df_medicare_hos <- rbind(df_medicare_hos,test_hos)

ggplot(data=df_medicare_hos, aes(x = reorder(provider_type, number), y=log(number))) +
  geom_bar(stat="identity", fill="steelblue") +
  geom_text(aes(label=number), hjust=0.9, color="black",
            position = position_dodge(0.9), size=4)+
  coord_flip() +
  xlab('Hospital type')+ 
  ylab('number of patients(log)') +
  theme_minimal() +
  facet_wrap( ~ type)
```
```{r}
#check target mean
mean(population_sample$readm_flag)
mean(df_medicare$readm_flag)
```


```{r}
# ----------------- 
# train population model
# -----------------

# we focus on readmission now. so we remove mortality and er_90days 
drops<- c('mortality_90', 'er_90days')
population_sample <- population_sample[,!(colnames(population_sample) %in% drops)]

# Add time related features
population_sample$clm_admsn_dt = as.Date(population_sample$clm_admsn_dt)
population_sample$nch_bene_dschrg_dt = as.Date(population_sample$nch_bene_dschrg_dt)
population_sample$month = months(population_sample$clm_admsn_dt,abbreviate = TRUE)
population_sample$week_of_dates = weekdays(population_sample$clm_admsn_dt,abbreviate = TRUE)
population_sample$days_before_admsn = population_sample$clm_admsn_dt-as.Date('2016-01-01')
population_sample$days_before_dschrg = population_sample$nch_bene_dschrg_dt - as.Date('2016-01-01')

# hold out test set
population_sample = population_sample[order(population_sample$clm_admsn_dt),]
size = nrow(population_sample)
train_valid_size = as.integer(round(size*0.8,digits=0))
test_size = as.integer(size - train_valid_size)
train_valid = population_sample[c(1:train_valid_size), ]
test = population_sample[c((train_valid_size+1):size), ]

# dataset for base model (remove time related features)
drops = c('clm_admsn_dt','nch_bene_dschrg_dt','month','week_of_dates','days_before_admsn','days_before_dschrg')
train_valid_base = train_valid[,!(colnames(train_valid) %in% drops)]
test_base = test[,!(colnames(test) %in% drops)]

train_valid_base$readm_flag=as.factor(train_valid_base$readm_flag)
train_valid_base[sapply(train_valid_base, is.character)] <- lapply(train_valid_base[sapply(train_valid_base, is.character)], 
                                       as.factor)

logistic = train(
  form = readm_flag ~ .,
  data = train_valid_base,
  trControl = trainControl(method = "cv", number = 5),
  method = 'regLogistic'
)
```

```{r}
temp=train_valid_base[c(101:102),c(1:6,8:10)]
reglogistic_prediction <- predict(logistic,
                                    newdata = temp, type = "prob")
```

```{r}
#testing
df_medicare_hostype <- df_medicare %>% group_by(provider_type) %>% summarise(number = length(provider_type), sample = as.integer(length(provider_type)/5) )

df_medicare__population_hostype <- population_sample %>% group_by(provider_type) %>% summarise(number = length(provider_type))
```