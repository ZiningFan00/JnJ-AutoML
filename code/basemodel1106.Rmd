---
title: "baselineModel"
output: html_document
---
```{r}
library(ggplot2)
library(tidyverse)
library(stringr)
library(GGally)
library(parcoords)
library(tidyr)
library(r2d3)
library(dplyr)
library(readr)
library(gridExtra)
library(plotly)
library(ade4)
library(data.table)
library(caret)
library(devtools) #inorder to use install_version
#most current version of xgboost can't be installed on the Rstudio server, thus
#install the older version: xgboost_0.90.0.2.tar.gz	2019-08-01 21:20	826K
#install_version("xgboost", version = "0.90.0.2", repost = "http://cran.us.r-project.org")
library(xgboost)
library(MLmetrics)#for calculating F1-score
library(ranger) #fast random forest
library(Boruta)
library(dummies)
```


```{r}
#install.packages('RJDBC')

## --------------------------------
## Sets Java Home
## --------------------------------
if (Sys.getenv("JAVA_HOME")!="")  Sys.setenv(JAVA_HOME="")


## --------------------------------
## Loads libraries
## --------------------------------
library(rJava)
options(java.parameters = "-Xmx8048m")
library(RJDBC)
library(DBI)


## --------------------------------
## Sets Java Home
## --------------------------------
if (Sys.getenv("JAVA_HOME")!="")
  Sys.setenv(JAVA_HOME="")


## --------------------------------
## Loads libraries
## --------------------------------
library(rJava)
options(java.parameters = "-Xmx8048m")
library(RJDBC)
library(DBI)


## --------------------------------
## General Variables
## --------------------------------
redShiftDriver <- JDBC("com.amazon.redshift.jdbc41.Driver", "RedshiftJDBC41-1.2.8.1005.jar", identifier.quote="`")
# put Redshift jar file in your home directory
resultSet <- data.frame()
username <- "zfan4"               ## Set VPCx / Redshift username - this is your J&J userID, for example mine is stong2  
password <- "19A3#a39F7py"            ## Set VPCx / Redshift password - this is the password you got from an encrypted email
rhealthDBName <- "saf"                ## Set dataset you want to connect to (full list provided here:  https://jnj.sharepoint.com/sites/PHM-GCSP-RND/RWE/Pages/rHEALTH-Database-Connectivity.aspx)


## --------------------------------
## Connection (do not change)
## --------------------------------
connectionString <- paste("jdbc:redshift://rhealth-prod-4.cldcoxyrkflo.us-east-1.redshift.amazonaws.com:5439/", rhealthDBName,"?ssl=true&sslfactory=com.amazon.redshift.ssl.NonValidatingFactory", sep="")
conn <- dbConnect(redShiftDriver, connectionString, username, password)


# dbListTables(conn)

res <- dbSendQuery(conn,'select * from saf.scratch_ctsaf2.np_col_hipfx_ads_v9') ## CTSAF2 is my scratch space
data <- fetch(res,n = -1) 

```

```{r}
rm(list=setdiff(ls(), "data")) #command to clean the environment list
gc()
df_medicare <- data
dim(df_medicare)
```

```{r}
#----------------
# Data Cleaning
#----------------

# Remove target information (247 -184 = 63)

drops <- c('mortality_365', 'readm_flag_365', 'er_365days', 're_claim_no',  're_clm_admsn_dt', 're_nch_bene_dschrg_dt','re_prvdr_num', 're_clm_utlztn_day_cnt', 're_clm_pmt_amt', 're_pdx', 're_ppx', 're_adm_source', 're_disc_status', 're_pdx_desc', 're_ppx_desc', 're_clm_admsn_dt_365', 're_nch_bene_dschrg_dt_365', 're_prvdr_num_365', 're_clm_utlztn_day_cnt_365', 're_clm_pmt_amt_365', 're_pdx_365', 're_ppx_365', 're_adm_source_365', 're_claim_no_365', 're_disc_status_365', 're_pdx_desc_365', 're_ppx_desc_365', 're_claim_no_365_up', 'readm_flag_365_up', 're_clm_admsn_dt_365_up', 're_nch_bene_dschrg_dt_365_up', 're_prvdr_num_365_up', 're_clm_utlztn_day_cnt_365_up', 're_clm_pmt_amt_365_up', 're_pdx_365_up', 're_ppx_365_up', 're_adm_source_365_up', 're_disc_status_365_up', 're_pdx_desc_365_up', 're_ppx_desc_365_up', 'er_claim_no_365', 'er_rev_cntr_dt_365', 'er_clm_thru_dt_365', 'er_prncpal_dgns_cd_365', 'er_pdx_desc_365', 'er_hcpcs_cd_365', 'er_hcpcs_desc_365', 'mortality_365_up', 'er_365days_up', 'er_claim_no_365_up', 'er_rev_cntr_dt_365_up', 'er_clm_thru_dt_365_up', 'er_prncpal_dgns_cd_365_up', 'er_pdx_desc_365_up', 'er_hcpcs_cd_365_up', 'er_hcpcs_desc_365_up','er_claim_no', 'er_rev_cntr_dt', 'er_clm_thru_dt','er_prncpal_dgns_cd','er_pdx_desc', 'er_hcpcs_cd', 'er_hcpcs_desc')


df_medicare <- df_medicare[, !(colnames(df_medicare) %in% drops)]


# Remove collinear features (184 - 149 = 33)
# also remove county region related information
drops <- c('cci_score_1825_days_b','elix_score_1825_days_b',  'fci_score_1825_days_b', 'follow_up_end_dt', 'follow_up_end_dt_365','ppx_desc', 'pdx_desc','hospital_name', 'fy', 'yr_adm', 'yr_disch', 'prvdr_state_name', 'prvdr_state_cd', 'prvdr_ssa_county_code', 'prov_vol_per_month', 'prvdr_home_hha_vol_month', 'prvdr_home_hha_vol_per', 'phy_vol_month', 'prvdr_urspa', 'prvdr_cbsa', 'prvdr_cbsa_desc', 'prvdr_msa','prvdr_msa_desc', "elix_cong_heart_fail_1825_days_b", "elix_periph_vas_dis_1825_days_b", "elix_paralysis_1825_days_b", "elix_copd_1825_days_b", "elix_aids_1825_days_b", "elix_met_cancer_1825_days_b", "fci_heart_attack_1825_days_b", "fci_obesity_1825_days_b", 'nch_bene_dschrg_dt','county', 'bene_cnty_cd',  'prvdr_division','prvdr_region','prvdr_region_cd', 'prvdr_div_code')

df_medicare <- df_medicare[, !(colnames(df_medicare) %in% drops)]


# Remove features same entry and unique entry (150 - 136 = 14)

drops <- c('version_id', 'cont_enroll_flag_1825b_89f', 'valid_date_of_death_1825b_89f', 'hmo_enroll_flag_1825b_89f', 'hmo_enroll_flag_365f','cont_enroll_flag_365f','at_physn_upin', 'op_physn_upin', 'ot_physn_upin',
           'desy_sort_key', 'claim_no', 'ot_physn_npi','at_physn_npi','op_physn_npi')


df_medicare <- df_medicare[, !(colnames(df_medicare) %in% drops)]



```

```{r}
#categorical regrouping

#disc_status

#Discharged to home/self-care
home = c("01", "21")
#Discharged to a hospital for care that wouldnâ€™t be covered under this episode
hospital_nc = c('04', '05', '63', '64', '65', '70')
#Left against medical advice or discontinued care. Patients who leave before triage or seen by physician
leave_early = '07'
#remove as 20 indicates the death of patients
remove = '20'
df_medicare$disc_status[!(df_medicare$disc_status %in% c(hospital_nc, home, leave_early, remove))] = 'post_acute_care'
df_medicare$disc_status[df_medicare$disc_status %in% home] = 'home'
df_medicare$disc_status[df_medicare$disc_status %in% hospital_nc] = 'hospital_nc'
df_medicare$disc_status[df_medicare$disc_status == leave_early] = 'leave_early'
df_medicare$disc_status[df_medicare$disc_status == remove] = 'remove'

#remove the row entries
df_medicare = df_medicare %>% filter(disc_status != 'remove')

#adm_source no regroup
#prncpal_dgns_cd: keep first digit
df_medicare$prncpal_dgns_cd = substr(df_medicare$prncpal_dgns_cd, 1, 1)

#icd_prcdr_cd1
hip = read.csv('icd_prcdr_cd1_hip', stringsAsFactors = FALSE)
hip = hip$icd_prcdr_cd1
df_medicare = df_medicare %>% filter(icd_prcdr_cd1 %in% hip)
df_medicare$icd_prcdr_cd1 = substr(df_medicare$icd_prcdr_cd1, 5, 5)
open = '0'
unkown = c('1', 'Z')
lap = c('3', '4', 'X')

df_medicare$icd_prcdr_cd1[df_medicare$icd_prcdr_cd1 == open] = 'open'
df_medicare$icd_prcdr_cd1[df_medicare$icd_prcdr_cd1 %in% unkown] = 'unkown'
df_medicare$icd_prcdr_cd1[df_medicare$icd_prcdr_cd1 %in% lap] = 'lap'
#clm_drg_cd no regroup
#gndr_cd
df_medicare$gndr_cd[df_medicare$gndr_cd == '1'] = 'M'
df_medicare$gndr_cd[df_medicare$gndr_cd == '2'] = 'F'
#bene_race
df_medicare$bene_race_cd[!(df_medicare$bene_race_cd %in% c('1','2'))] = 'Other'
df_medicare$bene_race_cd[df_medicare$bene_race_cd == '1'] = 'W'
df_medicare$bene_race_cd[df_medicare$bene_race_cd == '2'] ='B'
#drop disc_home_index as it duplicate with disc_status
df_medicare = df_medicare %>% select(-disc_home_index)
#provider_type no regroup needed
#hospital_name already drop
#prvdr_urgeo no regroup
#prvdr_region dropped due to too high level info
#prvdr_teaching_status no regroup

#bene_state_cd
bene_state_ab = read.csv('bene_state_cd',  colClasses=c("bene_state_cd"="character"),stringsAsFactors = FALSE )
df_join = left_join(df_medicare['bene_state_cd'], bene_state_ab, by = 'bene_state_cd')
df_medicare['bene_state_cd'] = df_join[, 3]
#bene_cnty_cd drop due to too low level detail
#prvdr_division drop due to too high level info
#prvdr_state_ab no regroup
#county drop due to too low level detail
write.csv(x = colnames(df_medicare), file = "colnames_population")
```


```{r}
# Remove missing value (439248 - 429599 = 9649)

# remove rows with missing value
df_medicare[df_medicare == -999] <- NA
df_medicare[df_medicare == 'NA'] <- NA
df_medicare <- df_medicare %>% drop_na(prvdr_num,prvdr_teaching_status,ma_pen_percent,prvdr_rday,ami_cabg)
```




```{r}
# The following code is to check whether there is still missing value left
t <- colSums(is.na(df_medicare))
t[t!=0]
```


```{r}

#-----------
# Hospital level and Population level Sampling
#-----------

##removing hospital with less than 100 observations and less than 10 positive or negative value for the target variables
keep = df_medicare %>% 
  group_by(prvdr_num) %>% 
  summarise(total = n(), re_pos = sum(readm_flag), re_neg = total - re_pos, er_pos = sum(er_90days), er_neg = total - er_pos, mor_pos = sum(mortality_90), mor_neg = total - mor_pos) %>% 
  filter(total > 99 & re_pos > 10 & re_neg > 10 & er_pos > 10 & er_neg > 10 & mor_pos > 10 & mor_neg > 10 ) %>% 
  pull(prvdr_num)
sample <- df_medicare %>% 
  filter(prvdr_num %in% keep)
```

```{r}
#one hot encoder
one_hot_name = c('disc_status', 'icd_prcdr_cd1', 'clm_drg_cd', 'gndr_cd', 'bene_race_cd', 'provider_type', 'prvdr_urgeo', 'prvdr_teaching_status')
df_one_hot = sample[, one_hot_name]
df_one_hot[] = lapply( df_one_hot, factor)
one_hot_levels = lapply(df_one_hot, levels)
saveRDS(one_hot_levels, "one_hot_levels.Rds")

dmy <- dummyVars(" ~ .", data = df_one_hot)
dmy_transform <- data.frame(predict(dmy, newdata = df_one_hot))

sample = cbind(sample, dmy_transform)
#drop original one hot cat column and one of dummy group for dummy class = 2
drop1 = c('gndr_cd.M', 'provider_type.Hospitals.participating.in.ORD.demonstration.project','prvdr_teaching_status.No')
sample = sample[, !(colnames(sample) %in% c(one_hot_name, drop1))]


```


```{r}
#write the qualified hospital number into csv file 1516
write.csv(x = keep, file = "prvdr_num_qualify")
```
```{r}
#read the qualified hospital number from the csv file
# n_to_keep = read.csv(file = "prvdr_num_qualify", colClasses=c("x"="character"))
# n_to_keep = n_to_keep$x
# col_to_keep = read.csv(file = "colnames_population", stringsAsFactors = FALSE)
# col_to_keep = col_to_keep$x
```

```{r}
set.seed(100)
#random sample % hospital based on the state
p_h = 0.05
keep <- sample %>% 
  group_by(prvdr_num) %>% 
  summarise(number = length(prvdr_num),state = unique(prvdr_state_ab)) %>%
  group_by(state) %>%
  sample_n(as.integer(ceiling(length(state)*p_h))) %>%
  pull(prvdr_num)

#Since there is only one "Hospitals participating in ORD demonstration project" prvdr_num = 450890b fits our previous criteria, thus must include it in our sample
if (! "450890" %in% keep){
  keep = c(keep, "450890")
}
sample <- sample %>% 
  filter(prvdr_num %in% keep)

## plots to test the sample
# t1 <- df_medicare %>%
#   group_by(prvdr_state_ab) %>%
#   summarise(num = length(prvdr_state_ab),hos_num = length(unique(prvdr_num)),type = "population")
# t2 <- hos_sample %>%
#   group_by(prvdr_state_ab) %>%
#   summarise(num = length(prvdr_state_ab),hos_num = length(unique(prvdr_num)),type = "sample")
# t <- rbind(t1,t2) 
# 
# ggplot(data=t, aes(x = reorder(prvdr_state_ab,num), y=log(num)))+
#   geom_bar(stat="identity",fill = "steelblue") +
#   coord_flip() +
#   xlab('state')+ 
#   ylab('number of patients(log)') +
#   facet_wrap(~ type) + 
#   theme_minimal()
# 
# ggplot(data=t, aes(x = reorder(prvdr_state_ab,hos_num), y=log(hos_num)))+
#   geom_bar(stat="identity",fill = "steelblue") +
#   coord_flip() +
#   xlab('state')+ 
#   ylab('number of hospitals(log)') +
#   facet_wrap(~ type) + 
#   theme_minimal()

population_sample <- sample
 
# Remove columns leaking hospital information
drops <- c('prov_vol_annual', 'prov_vol_per_month', 'prvdr_home_hha_vol', 'prvdr_home_hha_vol_month', 'prvdr_home_hha_vol_per', 'phy_vol_annual', 'phy_vol_month', 'op_phy_cum_exp', 'provider_type', 'hospital_name', 'prvdr_ssa_county_code', 'prvdr_urgeo', 'prvdr_urspa', 'prvdr_wi', 'prvdr_cola', 'prvdr_resident_to_bed_ratio', 'prvdr_rday', 'prvdr_beds', 'prvdr_dshpct', 'prvdr_dshopg', 'prvdr_dshcpg', 'prvdr_state_ab', 'bpci_lejr', 'cjr', 'bpci_ami_cabg', 'ami_cabg', 'prvdr_cbsa', 'prvdr_cbsa_desc', 'prvdr_msa', 'prvdr_msa_desc', 'prvdr_teaching_status', 'low_income_subsidy', 'poverty_per', 'grp_1', 'grp_2', 'grp_3', 'grp_4', 'grp_5', 'grp_6', 'grp_7', 'grp_8', 'grp_9', 'grp_10', 'unemp_percentage', 'no_of_snfs', 'ma_pen_percent', 'snf_per_capita')


#('fci_arthritis_1825_days_b', 'fci_osteoporosis_1825_days_b', 'fci_asthma_1825_days_b', 'fci_copd_1825_days_b', 'fci_angina_1825_days_b', 'fci_cong_heart_fail_1825_days_b', 'fci_heart_attack_1825_days_b', 'fci_neur_dis_1825_days_b', 'fci_stroke_1825_days_b', 'fci_diabetes_1825_days_b', 'fci_perif_vasc_dis_1825_days_b', 'fci_upper_gi_1825_days_b', 'fci_depression_1825_days_b', 'fci_anxiety_panic_1825_days_b', 'fci_visual_imp_1825_days_b', 'fci_hear_imp_1825_days_b', 'fci_ddd_1825_days_b', 'fci_obesity_1825_days_b','prior_inp_only_los', 'prior_irf_los', 'prior_ltcf_los', 'prior_snf_los', 'prior_hha_visits', 'prior_out_visits', 'total_prior_los',) should not be remove as entry are different within a hospital

hos_sample <- sample[, !(colnames(sample) %in% drops)]

```

```{r}
#write the sample of  qualified hospital number into csv file 1516
write.csv(x = keep, file = paste("prvdr_num_qualify_", p_h, sep =""))
```


```{r}

# Note all the Critical Access Hospitals has hospital name associate variables as N/A, such as prvdr_wi, prvdr_rday
# Also note only 2 Critical Access Hospital has over 100 observation and one with readmit only 8 positive.
# Other type of hospitals has less than 100 observations beside short-term and "Hospitals participating in ORD demonstration project" (only 1 hospital(361319) of this type has over 100 observation)
# test_hospital_type = data %>% filter(provider_type == "Critical Access Hospitals" )
# temp = test_hospital_type %>% 
#   group_by(prvdr_num) %>% 
#   summarise(total = n(), re_pos = sum(readm_flag), re_neg = total - re_pos, 
#             er_pos = sum(er_90days), er_neg = total - er_pos,
#             mor_pos = sum(mortality_90), mor_neg = total - mor_pos)
# test_hospital_type = df_medicare %>% filter(provider_type == "Hospitals participating in ORD demonstration project" )
# temp = test_hospital_type %>% 
#   group_by(prvdr_num) %>%
#   summarise(total = n(), re_pos = sum(readm_flag), re_neg = total - re_pos,
#             er_pos = sum(er_90days), er_neg = total - er_pos,
#             mor_pos = sum(mortality_90), mor_neg = total - mor_pos)



```


```{r}
# -------------------
# feature engineering
# -------------------

# Add time related features for later use and order data by date
population_sample$clm_admsn_dt = as.Date(population_sample$clm_admsn_dt)
population_sample$month = months(population_sample$clm_admsn_dt,abbreviate = TRUE)
population_sample$week_of_dates = weekdays(population_sample$clm_admsn_dt,abbreviate = TRUE)
population_sample = population_sample[order(population_sample$clm_admsn_dt),]

#change difftime object to numeric
population_sample$days_before_admsn = as.numeric(population_sample$clm_admsn_dt-as.Date('2016-01-01'), units="days")

#no need the days_before_dscharg as we already have length of stay and is removed from data in the collinearity section
#remove date column as we have convert it to number
drops = c('clm_admsn_dt')
population_sample = population_sample[,!(colnames(population_sample) %in% drops)]

#for later target encoder use
population_sample[sapply(population_sample, is.character)] <- lapply(population_sample[sapply(population_sample, is.character)], as.factor)
```


```{r}
# ----------------- 
# train validation test split for population level
# -----------------

# we focus on readmission now. so we remove mortality and er_90days 
drops<- c('mortality_90', 'er_90days')
population_sample <- population_sample[,!(colnames(population_sample) %in% drops)]
#rename the readm_flag as target here, so for other targets we can just change their name to target as well then able to use the following code
population_sample = population_sample %>% rename(target = readm_flag)

#create an empty data frame
train = population_sample[1,] %>% filter(prvdr_num == "empty")
val = population_sample[1,] %>% filter(prvdr_num == "empty")
test = population_sample[1,] %>% filter(prvdr_num == "empty")

# population train, val, test = sum of all hospital's train set, val, test
n_of_hos = unique(population_sample$prvdr_num)
for(h in n_of_hos){
  temp = population_sample %>% filter(prvdr_num == h)
  temp_0 = temp %>% filter(target == 0)
  temp_1 = temp %>% filter(target == 1)
  train_size_0 = as.integer(round(nrow(temp_0)*0.7, digits = 0))
  val_size_0 = as.integer(round(nrow(temp_0)*0.15, digits = 0))
  train_size_1 = as.integer(round(nrow(temp_1)*0.7, digits = 0))
  val_size_1 = as.integer(round(nrow(temp_1)*0.15, digits = 0))
    
  h_train = rbind(temp_0[c(1:train_size_0),],
                  temp_1[c(1:train_size_1),])
  h_val = rbind(temp_0[c((train_size_0+1):(train_size_0 + val_size_0)),],
                temp_1[c((train_size_1+1):(train_size_1 + val_size_1)),])
  h_test = rbind(temp_0[c((train_size_0 + val_size_0+1):nrow(temp_0)),], 
                 temp_1[c((train_size_1 + val_size_1+1):nrow(temp_1)),])
  
  train = rbind(train, h_train)
  val = rbind(val, h_val)
  test = rbind(test, h_test)
  
}

#for population model only
train <- train[, !(colnames(train) %in% c("prvdr_num"))]
val <- val[, !(colnames(val) %in% c("prvdr_num"))]
test <- test[, !(colnames(test) %in% c("prvdr_num"))]

```


```{r}
# ----------------- 
# Data Preprocessing Function
# -----------------

#target encoding for categorical features

addrandom = function(x){
  return(x + runif(1))
}
targetencode = function(indices, df){
  result = c()
  df$fake_target = sapply(df$target, addrandom)
  for (i in indices){
    lookup = df %>% group_by_at(i) %>% summarise(mean(fake_target))
    result = c(result, lookup)
  }
  return(list(result, mean(df$fake_target)))
}

targetencode_transform = function(indices, result, df, dropna = TRUE, targetmean){
  j = 1
  for (i in indices){
    lookup = data.frame(result[j], result[j+1])
    cat_colname = colnames(df)[i]
    df_targetment = left_join(df[cat_colname], lookup, by = cat_colname)
    df[i] = df_targetment[, 2]
    j = j +2
  }
  if (dropna & sum(is.na(df))){
    print("There is missing categorical class")
    t <- colSums(is.na(df))
    print(t[t!=0])
    #df = df %>% drop_na()
    df[is.na(df)] = targetmean
  }
  return(df)
}
```

```{r}
# ----------------- 
# Train Model function
# -----------------

fitModel = function(df,type){
  
  folds <- 5
  cvIndex <- createFolds(df$target, folds, returnTrain = T)
  y_train = df$target
  st = Sys.time()
  if(type == 'rlg'){
    trcontrol = trainControl(index = cvIndex,
                              method = "cv",
                              number = folds,
                              summaryFunction = prSummary,
                              classProbs = TRUE)
    set.seed(0)
    fit <- train(
      form = target ~., 
      data = df,
      trControl= trcontrol,
      method = 'regLogistic',
      metric = "F")
  }
  else if(type == 'rf'){
    trcontrol = trainControl(index = cvIndex,
                              method = "cv",
                              number = folds,
                              summaryFunction = prSummary,
                              classProbs = TRUE)
    set.seed(0)
    fit <- train(
      form = target ~., 
      data = df,
      trControl= trcontrol,
      method = 'ranger',
      metric = "F")
  }
  else if(type == 'xgb'){
    df = df %>% select(-target)
    X_train = xgb.DMatrix(as.matrix(df))
    
    trcontrol = trainControl(
      index = cvIndex,
      method = "cv",
      number = folds,  
      allowParallel = TRUE,
      verboseIter = FALSE,
      classProbs = TRUE,
      summaryFunction = prSummary,
      returnData = FALSE
    )
    set.seed(0) 
    fit = train(
      X_train, y_train,  
      trControl = trcontrol,
      nthread = 1, #avoid double parallel computing causing the run time to expand 
      method = "xgbTree",
      metric = "F"
    )
  }
  ed = Sys.time()
  print(ed - st)
  return(fit)
}
```

```{r}
# ----------------- 
# F1 score function
# -----------------

#Note if TP + FP ==0 (when we all predict 0), precision is undefined.
#Precision = TP / (TP+FP)
#Recall = TP/(TP + FN)

#if TP + FN == 0 (when sample only have 0), recall is undefined
#F1 = 2 * Precision * Recall/ (Precision + Recall) -> undefined if TP = 0


# ConfusionMatrix
#         ACTUAL
#        1     0
# P    +----+----+
# R  1 | TP | FP |
# E    +----+----+
# D  0 | FN | TN |
#      +----+----+

# since if we predict all as Class 0 or as Class 1, F1_score will return error, plus we don't want a model that predict all as 0 or 1, thus set its f1 score = -1 indicate bad model
unbias_f1 = function(pred, yval){
  f1 = -1
  if (sum(pred)!= 0 & sum(pred)!= length(pred)){
    f1 = F1_Score( y_pred = pred, y_true = yval, positive = 1)
  }else if(sum(pred) == sum(yval)){
    f1 = 1
  }
  if(is.na(f1)){
    f1 = 0
  }
  return(f1)
}

# ----------------- 
# Prediction function
# -----------------
#scoring function returns a list of best Cross_Validation Score, Validation Set F1 scores, Log loss, AUC, and Accuracy with input model, X validation and y validation.
scoring = function(model, X_val, y_val){
  pre_class <- ifelse(predict(model, newdata = X_val, type = "raw") == "Class_0",0,1)
  pre_prob <- predict(model, newdata = X_val, type = "prob")$Class_1
  return(c(max(model$results$F, na.rm=TRUE), unbias_f1(pre_class, y_val), LogLoss(pre_prob, y_val), AUC(pre_prob, y_val), Accuracy(pre_class, y_val)))
}

```

```{r}
#data preprocess
cat_name = names(Filter(is.factor, train))
cat_index = match(cat_name, names(train))
tgen = targetencode(cat_index, train)
train = targetencode_transform(cat_index, tgen[[1]], train, targetmean = tgen[[2]])
val = targetencode_transform(cat_index, tgen[[1]], val, targetmean = tgen[[2]])
test = targetencode_transform(cat_index, tgen[[1]], test, targetmean = tgen[[2]])

#change target value to factor and assigned positive class to class1
train$target =as.factor(train$target) 
levels(train$target)= c("Class_0", "Class_1")
train$target <- factor(train$target, levels=rev(levels(train$target)))

```

```{r}
#write the sample of  qualified hospital number into csv file 1516
saveRDS(tgen, "pop_tgen.Rds")
a = readRDS(file = "pop_tgen.Rds")
```

```{r}

# This is the function that takes in the train set with the desire sample size with down/up/not sampling
# the class1 of the target. Then split the train variables into  base, Boruta, Boruta + time, base + time combination.
# Finally, train each combination with regularize logistic regression, random forest, and XGBoost model, 
# and evaluate the F1 score base on input validation set.
# The output is a list contain result summary data frame and a list of the fitted models

population_model = function(train, val, imbalance = "NA", sm_train_size, sm_val_size){
  train = train[c(1:sm_train_size),]
  val = val[c(1:sm_val_size),]
  if(imbalance == "down"){
    set.seed(9560)
    train <- downSample(x = train[, !(colnames(train) %in% c("target"))], y = train$target)
    train = train %>% rename(target = Class)
  }else if(imbalance == "up"){
    train <- upSample(x = train[, !(colnames(train) %in% c("target"))], y = train$target)
    train = train %>% rename(target = Class)
  }
  #base, Boruta, Boruta + time, base + time as index 1, 2, 3, 4
  train_set = list()
  val_set = list()
  
  ## dataset for base model (remove time related features)
  time_feature = c('month','week_of_dates','days_before_admsn')
  train_set[[1]] = train[,!(colnames(train) %in% time_feature)]
  val_set[[1]] = val[,!(colnames(val) %in% time_feature)]
  
  ## Boruta with no time data set
  boruta_start_time <- Sys.time()
  sigtest <- Boruta(target~. , data = train, holdHistory=FALSE, doTrace=2)
  boruta_end_time <- Sys.time()
  boruta_features = c(getSelectedAttributes(sigtest), "target")
  train_set[[2]] = train[, boruta_features]
  val_set[[2]] = val[, boruta_features]
  print(boruta_end_time - boruta_start_time)
  
  ## Boruta with time data set
  boruta_time_features = c(boruta_features, time_feature)
  train_set[[3]] = train[, boruta_time_features]
  val_set[[3]] = val[, boruta_time_features]
  
  ## Base with time data set
  train_set[[4]] = train 
  val_set[[4]] = val 
  
  #training models
  model_types = c("rlg", "rf", "xgb")
  X_types = c("Base", "Boruta", "Boruta_time", "Base_time")
  model_X_types = c()
  cv_f1s = c()
  val_f1s = c()
  loglosses = c()
  AUCs = c()
  accuracys = c()
  models = list()
  st = Sys.time()
  rt= c()
  rt_unit = c()
  j = 1
  for(type in model_types){
    for(i in c(1:4)){
      model_X_type = paste(type, X_types[i], sep= "_")
      model_X_types = c(model_X_types, model_X_type)
      train_df = train_set[[i]]
      y_val = val_set[[i]]$target
      X_val = val_set[[i]] %>% select(-target)
      if(type == "xgb"){
        X_val = xgb.DMatrix(as.matrix(X_val))
      }
      st_i= Sys.time()
      model = fitModel(train_df, type)
      t = Sys.time()-st_i
      rt_unit = c(rt_unit, units(t))
      rt = c(rt, t)
      sc = scoring(model, X_val, y_val)
      cv_f1s = c(cv_f1s, sc[1])
      val_f1s = c(val_f1s, sc[2])
      loglosses = c(loglosses, sc[3])
      AUCs = c(AUCs, sc[4])
      accuracys = c(accuracys, sc[5])
      models[[j]] = model
      j = j +1
    }
  }
  print(Sys.time()-st)
  
  #Summary_result
  summary_result <- data.frame("Type" =model_X_types, "cv_f1" = cv_f1s, "val_f1" = val_f1s, 
                               "logloss" = loglosses, "AUC" = AUCs,
                               "accuracy" = accuracys, "runtime" = rt, 
                               "time_unit" = rt_unit, stringsAsFactors = FALSE)
  summary_result[is.na(summary_result)] <- 0
  best_cvf1 = max(summary_result$val_f1)
  best_index = which.max(summary_result$val_f1)
  best_model_name = model_X_types[best_index]
  best_model = models[[best_index]]
  
  print(paste("The best model is:", best_model_name, "with validation f1 score:", best_cvf1, sep = " "))
  result = list(summary_result, models, best_model, boruta_features)
  return(result)
}
```





```{r}
#population_model = function(train, val, imbalance = "NA", sm_train_size, sm_val_size)
sm_train_size = 3000
sm_val_size = 500
# summary_imbalance1000 = population_model(train, val, imbalance = "NA", sm_train_size, sm_val_size )
# summary_imbalance1000_result = summary_imbalance1000[[1]]
# imbalance1000_models =  summary_imbalance1000[[2]]
#
# summary_up1000 = population_model(train, val, imbalance = "up", sm_train_size, sm_val_size )
# summary_up1000_result = summary_up1000[[1]]
# up1000_models =  summary_up1000[[2]]

summary_down05_3000 = population_model(train, val, imbalance = "down", sm_train_size, sm_val_size )
summary_down05_result_3 = summary_down05_3000[[1]]
down05_models_3 =  summary_down05_3000[[2]]
```

```{r}
best_index = which.max(summary_down05_result$val_f1)
best_model = down05_models[[best_index]]
best_model_name = summary_down05_result$Type[best_index]
saveRDS(best_model, paste(best_model_name, "_05.Rds", sep=''))
```


```{r}
set.seed(9560)
rf50_st = Sys.time()
train_down <- downSample(x = train[, !(colnames(train) %in% c("target"))], y = train$target)
train_down = train_down %>% rename(target = Class)
model_rf50 = fitModel(train_down, "rf")
saveRDS(model_rf50, "model_rf50.Rds")
print(Sys.time() - rf50_st)

```

```{r}
y_val = val$target
X_val = val %>% select(-target)
sc = scoring(model_rf50, X_val, y_val)
```
```{r}
summary_result_rf50 <- data.frame("Type" =c("rf_base_time"), "cv_f1" = c(sc[1]), "val_f1" = c(sc[2]) , 
                               "logloss" = c(sc[3]), "AUC" = c(sc[4]),
                               "accuracy" = c(sc[5]), "runtime" = c("22.98896"), 
                               "time_unit" = c("mins"), stringsAsFactors = FALSE)
```
```{r}
a = readRDS(file = "model_rf50.Rds")
```

